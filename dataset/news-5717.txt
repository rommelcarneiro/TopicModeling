


Would you enjoy reading this more if it were written by a machine? Spoiler alert: It’s not. But whether created by human or computer, what do we want from news?

As Mike Isaac reports, Facebook has published detailed information about how it chooses the news topics it puts before the 1.6 billion people on the social network. The company released the information under some duress, prodded by accusations that it was suppressing reports from conservative news outlets.

Basically, Facebook said it used a base of computers putting possible stories from various places in front of human editors, who direct how these will be presented and displayed. Facebook said that it had a system of “checks and balances” that made sure a number of viewpoints were examined, and that it did not allow editors to “discriminate against sources of any political origin, period.”

It’s unclear whether the people who think Facebook did wrong will be appeased. All too often, where modern media is concerned, the general public assumes there is bias of one form or another. And Facebook did not seem to have sufficient details about how it made sure a human didn’t carry out a grudge by omitting one story or another.

There is a deeper issue at play as well, which has to do with the reasons Facebook is putting up the stories in the first place.

Like Google, Facebook makes money by putting up ads concerning things its computers think you are interested in. And like Google, the content (search results or friend’s updates, depending on the company) that goes with the ads is chosen based on previous behavior.

There are several reasons for this, including giving you pleasure and not stressing or boring you with dissonance.

That is problematic where news is concerned, at least if the reader is seeking an objective viewpoint: Since new information can force us to change our minds, we have to want, on some level, to be stressed if we’re looking to be fully informed. In a slower-moving world, this was known as changing your mind.

Is that what people want from news in a click-paced online world, though? The rise and success of specialty news outlets, which largely confirm their readers’ points of view, indicate that many people want to hear about the world, but through filters that affirm how they already feel about things.

Arguably, it was ever thus, and the right or the left had their own journals that people read. But the use of computer algorithms that know what you like stand to make it much more so.

Facebook may struggle to take news from a lot more points of view, but that doesn’t mean it’s going to put them in front of you.


