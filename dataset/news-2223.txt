


There are many moments throughout my average day that, lacking print reading material in a previous era, were once occupied by thinking or observing my surroundings: walking or waiting somewhere, riding the subway, lying in bed unable to sleep or before mustering the energy to get up.

Now, though, I often find myself in these situations picking up my phone to check a notification, browse and read the internet, text, use an app or listen to audio (or, on rare occasions, engage in an old-fashioned “telephone call”). The last remaining place I’m guaranteed to be alone with my thoughts is in the shower.

“Finding moments to engage in contemplative thinking has always been a challenge, since we’re distractible,” said Nicholas Carr, author of “The Shallows.” “But now that we’re carrying these powerful media devices around with us all day long, those opportunities become even less frequent, for the simple reason that we have this ability to distract ourselves constantly.”

Neuroplasticity (or the brain’s ability to change) due to technological use is a hot topic. Usually the tone is alarmist, though sometimes it’s optimistic.

Take video games: One study revealed improvements in memory and focus for older adults when playing a simple road-racing game. In another study, playing Super Mario 64 was observed to yield increases in gray matter in regions of the brain associated with memory, planning and spatial navigation.

But these cognitive abilities are distinct from mentally sequestered rumination. In a world in which a phone or computer is rarely more than arm’s length away, are we eliminating introspection at times that may have formerly been conducive to it? And is the depth of that reflection compromised because we have retrained ourselves to seek out the immediate gratification of external stimuli?

A few neuroscientific studies reveal the extent to which we are dependent on our electronic devices and suggest how, in doing so, we may be impairing our reflective abilities. A 2015 paper in the journal PLOS One measured smartphone use via an app from participants ages 18 to 33 and also asked them to report their estimates.

If the data is any indication, most of us use our phones more than we think: Participants estimated an average of 37 uses throughout the day (anything that turns on the screen, from hitting snooze to making a call), but the actual number was around 85. The slight majority took less than 30 seconds. (Participants also underestimated duration of use by about an hour — the real total was 5.05 hours — which included phone calls and listening to music when the screen was off.)

If you are awake for 16 hours, turning on or checking your phone 85 times means doing so about once every 11 minutes (and doesn’t account for internet use on a computer), and 5.05 hours is over 30 percent of the day. What might be the effect on reflection of this compulsive behavior?

In 2010, researchers led by Dr. Stephen Fleming at the Wellcome Trust Center for Neuroimaging at University College London published a paper in the journal Science in which they correlated introspective ability with the amount of gray matter in the prefrontal cortex. (Introspective ability was defined for the study as the accuracy of measuring one’s own performance on a visual-perception task, a sign of metacognition, or “thinking about thinking.”)

Using this information about the prefrontal cortex, Brian Maniscalco and Hakwan Lau published a paper in Neuroscience of Consciousness in 2015 that measured introspective ability while subjects were either able to focus on one task or distracted by a difficult second task. Being distracted by the second task didn’t hurt actual performance on the first task, but it did impair the subjects’ ability to be introspective (again, by accurately self-reporting how they did). The finding supports previous widespread evidence that multitasking leads to lower cognitive performance. (With, again, other studies showing some beneficial effects of multitasking.)

It is therefore “a reasonable conjecture,” Dr. Fleming said, if we think of navigating the world — physically, as a flâneur might, or mentally, when pondering something — as a “first task” and looking at one’s phone as a “second task,” that the latter hinders our capacity to reflect.

“The prefrontal cortex is good at doing one thing at a time,” he said. “If you put people in a dual-task setting, part of the reason things become impaired is because that secondary task interferes with the functions involved in introspection.”

It seems counterintuitive to say that we are entering an unreflective cultural phase, as our time tends to be criticized for its self-absorption. But our solipsism is frequently given outward expression rather than inward exploration, with more emphasis than ever before on images. When there is text, new media such as Instagram commonly sideline the role of language.

The selfie is too easy a fish to shoot in this particular barrel, but consider the tweet, its name phonically close to “thought.” Its brevity is the perfect length for an aphorism and little more (unless someone rattles off a sequence of tweets).

For a certain percentage of the population, the thoughts that they may have kept private in a pre-smartphone age — letting them marinate and perhaps deepen till they could no longer be articulated in fewer than 140 characters — are now ejected into a public forum.

Moreover, the internet typically rewards speed over all else, a quality at odds with deliberative thought — and our appetite for velocity is only increasing as data transfer rates improve. In 2006, Forrester Research found that online shoppers expected web pages to load in under four seconds. Three years later, the number was shaved to two seconds; slower web pages led many shoppers to look elsewhere.

By 2012, Google engineers had discovered that when results take longer than two-fifths of a second to appear, people search less, and lagging just one quarter of a second behind a rival site can drive users away.

“That hints at the way that, as our technologies increase the intensity of stimulation and the flow of new things, we adapt to that pace,” Mr. Carr said. “We become less patient. When moments without stimulation arise, we start to feel panicked and don’t know what to do with them, because we’ve trained ourselves to expect this stimulation — new notifications and alerts and so on.”

What this often translates to in the discourse of the internet is demand for immediate and perfunctory “hot takes” rather than carefully weighed judgments, whether they’re about serious or superficial matters.

Mr. Carr also noted counterarguments: Formulating relatively simple thoughts on the internet can yield more complex ones through real-time exchanges with others, and people whose reflex is to post a notion hastily rather than let it sit may not have been the most deliberative thinkers in a pre-smartphone time, either.

Nevertheless, he sees our current direction as indicative of “the loss of the contemplative mind,” he said. “We’ve adopted the Google ideal of the mind, which is that you have a question that you can answer quickly: close-ended, well-defined questions. Lost in that conception is that there’s also this open-ended way of thinking where you’re not always trying to answer a question. You’re trying to go where that thought leads you. As a society, we’re saying that that way of thinking isn’t as important anymore. It’s viewed as inefficient.”

Mr. Carr observed that, for decades, Rodin’s 1902 sculpture “The Thinker” epitomized the highest form of contemplation: a figure with an imposing physique staring abstractly downward, hunched over to block out distraction, frozen because it’s a statue, of course, but also because deep thinkers need time and don’t fidget. It’s hard to imagine a postmodern update called “The Tweeter” being quite so inspirational.


