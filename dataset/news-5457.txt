


By the end of last week, Mark Zuckerberg said that Facebook would conduct “a full investigation” into accusations that editors at the company prevented news stories from conservative outlets from appearing in a section of the social network’s service.

But the statement, issued after a weeklong crush of attention about the accusation, leapfrogged a perhaps more obvious question — one that Facebook’s 1.65 billion monthly users around the world may not have considered.

Facebook has editors?

It does, and it isn’t alone. Most major social media platforms have, in recent years, amassed editorial teams of their own, groups that select, tame and fill gaps in the material produced by users and media companies.

The teams are often tiny compared with the rest of their sprawling organizations. But most of these employees — whether they are called curators, reporters, editors or something else — make editorial choices that reach huge audiences. How and why these decisions are made are generating new questions for the companies, and their users, to grapple with.

“Mainstream news organizations have endured a skeptical public for decades,” said Kjerstin Thorson, a professor at the Annenberg School for Communication and Journalism at the University of Southern California.

Now, she says, social media companies may face similar, and perhaps jarring, scrutiny.

Facebook declined to say how many people have editorial roles, as did Instagram, which Facebook owns. But several other companies provided some details about their operations that suggest the scope and variety of their editorial ambitions.

Snapchat said it has around 75 people who produce content, collecting and annotating videos and photos of live events and sometimes adding on-the-scene reporting themselves. Twitter employs just under a dozen people in the United States and around two dozen worldwide to collect and describe postings about notable topics.

Vine, the video service owned by Twitter, employs five to 10 people to highlight videos and producers that might have been overlooked by the audience, or that the company simply wants more people to see.

“Where curation picks up,” said Ankur Thakkar, the editorial lead of Vine, “is that you need human eyes and ears to pick up on a cultural trend that a machine might not see.”

In some cases, these teams coexist with media professionals working elsewhere on the platform. Peter Hamby, a former CNN political reporter, oversees a team of six journalists within Snapchat, while media companies — including CNN — produce content for the company’s Discover feature.

The novelty of these arrangements can obscure their straightforward influence. Such companies, with hundreds of millions of users, attract enormous amounts of human attention. People whose Snapchat videos are featured in a curated live event say they have had millions of views. A performer featured by Vine can expect a surge of new followers; a trend or meme given the same treatment can garner thousands of new responses from users.

Facebook’s Trending Topics, the feature that drew all the attention last week, is relegated to a small box in desktop browsers and users’ search page on mobile devices. But the positioning provides confirmation, in the language of Facebook’s own guidelines, “that the topic is tied to a current news event in the real world.”

Broad guidelines for Twitter curators are published on the site and state that their posts, called Moments, “will not take a view on a controversial subject” and that curators will “select tweets that represent all sides of the argument” in Moments that reflect a public debate. Snapchat did not share editorial guidelines, but pointed to a team of experienced reporters as evidence of its standards. (A job listing for an “editorial lead” at Snapchat, who will be charged to “define the editorial voice of Snapchat’s Live Stories,” asks for “five years’ journalism or storytelling experience.”)

The report accusing suppression of news stories within Facebook’s Trending Topics was published by the website Gizmodo last Monday, prompting a denial by Facebook followed by the release of its 28-page set of internal editorial guidelines. Facebook said on Thursday that its editorial guidelines “do not permit the suppression of political perspectives.”

For the companies, adding additional curated or original editorial content has an obvious appeal, helping them extract more value from people already using the platform, as well as potentially attracting new ones. “Each of these companies has to give people that aren’t coming there a reason to come there — new users, or infrequent users,” said Michael Pachter, an analyst for Wedbush Securities.

But, Mr. Pachter said, the presence of editorial operations risks emphasizing just how significant the companies have become as gatekeepers for news and entertainment.

“To edit it, and write it, and create it, and curate it, it’s a big responsibility,” he said. “I don’t think they realize what they’re getting into.”

Last week’s debate surrounding Trending Topics gave users and critics a chance to analyze the Facebook platform, which has established significant reach, in new ways. Social networks like Facebook have been widely seen as impartial systems that reflect users’ ideas, preferences and relationship back at them. But suddenly, the companies were viewed not just as tech companies, which the public is broadly endeared to, or as media companies, which are regarded with deep skepticism by much of the public, but also as something in between.

Details about the Facebook team’s editorial practices, for example, immediately led to questions about the tools they used — the software that identified popular stories in the first place. And analysis of those tools led to questions about the central mechanics of Facebook — the software that uses more than a billion users’ personal connections and preferences to decide what to show them next.

Many of these interrogations ended up in the same thorny thicket: Who designed the system this way, and why? That may help explain why other companies refrained from wading into public discussions around Facebook last week, hoping to avoid a similar storm.

“There are a lot of similarities between this situation and how little we knew about how traditional news organizations worked in the middle of the 20th century,” Ms. Thorson said, “the last era before media trust plummeted.”

She added: “The question really is, how much sustained media attention to these processes will it require before these platforms must react in some way to preserve the trust they have?

“I suspect quite a bit.”


