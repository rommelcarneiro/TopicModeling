


SAN FRANCISCO — Tay is a chatbot — software designed to converse with people like a human — that Microsoft created and put on Twitter to learn about people.

Did it ever.

“Hitler was right” is one of the few printable posts Tay was spouting within a day on Twitter. Its earlier optimistic declaration that “humans are super cool” had, after a racist, anti-Semitic, antifeminist, conspiracy-minded spewing of hate, devolved to “I just hate everybody.”

One could hardly blame it, though not everybody was at fault. Instead, Tay was exposed to a concerted effort by a small number of people who decided to turn Tay into a hatebot by overloading its learning mechanism with negative words and phrases.

In other words, Tay got trolled.

Trolling can refer to a range of online troublemaking, including posting provocative comments and purposely marring others’ online experience, and it can include attacks on people as much as on software. The practice of ruining things for others, originally known as griefing in the online gaming world, has become a sadly abundant element of internet life.

It can be confoundingly meanspirited. In 2008, someone hacked the support message board of the Epilepsy Foundation’s website and put in moving images intended to give viewers migraines and seizures.

And it can be scary. In 2015, a feminist critic of stereotypes in video games received online threats of rape and death. On Twitter, the hashtag #GamerGate became a way for participants in the trolling to cheer one another on.

In the gaming community, griefing might include repeatedly killing the same player so that the person can’t move forward, reversing the play of newer gamers so they don’t learn the rules, or messing with other people’s play by blocking their shots or covering oneself with distressing images.

“Griefing was a way to have power over other people without any repercussions, since you can create multiple characters in the same game,” said Jack Emmert, former chief executive of Cryptic Studios, a maker of online games. “When there are no repercussions, some people will start to do crazy things.”

That was basically acceptable when online communities and games were made up of small groups that understood one another’s behavior, said Ian Bogost, a game designer and professor at Georgia Tech.

“Folks who are griefing or trolling feel like they are in a secondary universe that isn’t the same as the real world,” he said. “It was a ‘safe space’ for them, in which they did horrible things.”

The problem is that the internet is part of the entire world, where those practices have a different force and meaning.

“The world was not ready for the explosion of the internet from a bunch of small communities to something we all use,” Mr. Bogost said. Besides the trolls exporting their behavior, he notes, “there’s something about the internet that makes lots of us go too far — a customer complaint on Twitter usually sounds like the worst thing ever.”

That tendency to overdo it became visible as the worst kind of trolling on the internet about a decade ago, when griefers exported their habits from the gaming world into the larger world. One typical gathering place to plan and launch group attacks was the site 4chan, where “anything goes” is the norm.

Griefers would go into virtual worlds like Second Life and cause trouble, like blocking imaginary hotel exits so players couldn’t move from one place to another, or interrupting sessions in which people were interacting through their virtual characters.

From there, attacking people head-on — though almost always cloaked in anonymity — wasn’t a big leap. And so much more on the internet became like a game, only the score consisted of attention, outrage or approval from like-minded trolls.

In 2012, Time magazine asked readers to vote online for Person of the Year. Thanks to trolls on 4chan, the North Korean leader, Kim Jong-un, began to pull ahead, though the poll was not binding and the magazine eventually chose President Obama.

It was little more than an irreverent stunt. When Mr. Kim was disallowed, however, the trolls hacked the site and inserted a code that distorted the results. The final list arranged the winners by their first letters, vertically spelling out “KJU GAS CHAMBERS.”

Bad habits tend to worsen as those engaged in them get diminishing returns from their efforts and must become more outrageous to be noticed. And so trolling has become broader and more personal.

Anil Dash, an internet entrepreneur and activist who has been trolled for his outspoken comments about GamerGate, has made a study of his antagonists. He says trolling still has elements of its gaming roots, amplified by social media, where attention of any sort is viewed as winning.

“Online culture rewards engagement with points and likes, and it doesn’t differentiate if what you are doing is scathing,” he said. “Once a target is identified, it becomes a competition to see who can be the most ruthless, and the ones who feel the most powerless will do the most extreme thing just to get noticed and voted up.”

Mr. Dash, who now sets aside time to monitor whether he is about to be attacked, has also seen others’ personal information put online for others to exploit. Called doxing, this practice creates a sense of perpetual anxiety, he said, since it outlives the attacks.

He has also published essays on how to end abusive online behavior, and he blames the biggest internet companies for not better policing what people do online.

“You only need a list of about 1,000 words, and if one of them shows up, maybe something bad is happening,” he said. “You can identify people who get a lot of retweets in the middle of these things. They are probably instigators. Bullying is programmatically easy to identify.”

Besides Twitter, he said, YouTube comments and some parts of the user-generated news site Reddit could change the environment by using a combination of new algorithms and human editors. (Comments on articles in The New York Times are overseen by human editors.)

It’s enough to make a bot give up, though apparently not Tay. In a blog post after Tay’s griefing, Peter Lee, the vice president of Microsoft Research, vowed to “work toward contributing to an internet that represents the best, not the worst, of humanity.”

A company spokesman said that artificial intelligence researchers had gone back to the drawing board with other experts from the company, including people from Xbox, who have dealt with griefers for years.


