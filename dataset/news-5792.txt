


SAN FRANCISCO — Facebook, the largest social media network, published internal editorial guidelines on Thursday, the company’s latest attempt to rebut accusations that it is politically biased in the news content it shows on the pages of its 1.6 billion users.

The 28-page document details how both editors and computer algorithms play roles in the process of picking what should appear in the “Trending Topics” section of users’ Facebook pages.

Facebook describes a list of processes it uses to display some of the most popular content across the network, including relying on algorithms to detect up-and-coming news trends as well as a team of editors who, much like a newsroom, direct how those topics are presented and decide what should be displayed to people who regularly use the service.

As the guidelines make clear, at practically every point in the process, a human editor is given the leeway to exercise his or her editorial influence.

The document was released just days after a report on the tech news site Gizmodo said Facebook editors had intentionally “suppressed” news topics from conservative publications trending across the network. The report also said editors were able to artificially inflate the importance of other topics by “injecting” them into the Trending section of users’ Facebook pages.

Since those claims surfaced, Facebook has been questioned by news sites across the political spectrum and by legislators in Washington. On Thursday, critics urged the company to consider the biases of its editors.

“As long as Facebook is hiring editors who lean left politically, those stories are going to get preferential treatment,” Erick Erickson, former editor in chief of the conservative website RedState and founder of another conservative site called The Resurgent, said in an email. “I’d hope that Facebook would take care to consider all views and all news.”

The company has continued to deny accusations of political bias and pointed to editorial rules that discourage Trending Topics staff members from taking one viewpoint or another.

“The guidelines demonstrate that we have a series of checks and balances in place to help surface the most important popular stories, regardless of where they fall on the ideological spectrum,” Justin Osofsky, vice president for global operations at Facebook, said in a company blog post on Thursday. “Facebook does not allow or advise our reviewers to discriminate against sources of any political origin, period.”

The Guardian first reported on Facebook’s editorial guidelines.

As Facebook has noted several times this week, algorithms drive much of the decision-making for its Trending Topics, according to the documents. And the company said it has not found evidence that any editor intentionally manipulated the section to suppress conservative content.

But the guidelines, which have never before been made public, give insight into how editors guide and discover news items being shared widely across the social network, and how those editors decide what to promote inside the Trending Topics section.

While algorithms determine the exact mix of topics displayed to each person, based on that user’s past actions on Facebook, a team of people is largely responsible for the overall mix of which topics should — and more important, should not — be shown in Trending Topics.

For instance, after algorithms detect early signs of popular stories on the network, editors are asked to cross-reference potential trending topics with a list of 10 major news publications, including CNN, Fox News, The Guardian and The New York Times.

Editors are also entrusted to spot potentially large news stories bubbling up outside Facebook by using an algorithm that trawls more than a thousand automated feeds, up to and including competitors like YouTube and Reddit, along with traditional news sites.

These editors can then introduce those trends into the Topics box, in order to “connect people to conversations on Facebook about newsworthy events as quickly as possible,” according to Facebook.

One former Facebook Trending Topics editor, who spoke under condition of anonymity because this person had signed a nondisclosure agreement with the company, said it was up to the editors’ discretion to promote newsy topics that were not quite percolating on Facebook.

The guidelines were first created in 2014, according to a Facebook spokeswoman, and have continuously been updated over the last year and a half.

On Tuesday, Senator John Thune, Republican of South Dakota, sent a letter of inquiry to Mark Zuckerberg, chief executive of Facebook, asking the company to further explain its editorial guidelines and to disclose whether there was “any level of subjectivity associated with” the Trending Topics section.

Facebook said it planned to address Senator Thune’s questions, and that it was “continuing to investigate whether any violations took place.”

However, experts warn that fearing bias in human editors and trusting the neutrality of algorithms is a faulty premise. Algorithms are, after all, created by humans and therefore susceptible to the same unconscious biases.

“Imagine going back in time to the 1950s and building a machine-learning algorithm, based on historical data at the time, to decide who would be ‘successful’ in their jobs,” said Cathy O’Neil, a data scientist and author of the forthcoming book “Weapons of Math Destruction,” a study of how algorithms exacerbate inequality. “It would be only white men, because the data it had was picking up the sexism and racism of the time, and the data was informing the definition of success.”

Facebook’s stance, as it made clear on Thursday, is that the best way to handle these issues is with a mix of both human and machine input.

“Every tool we build is designed to give more people a voice and bring our global community together,” Mark Zuckerberg, chief executive of Facebook, said in a post to his Facebook page on Thursday evening. “For as long as I’m leading this company, this will always be our mission.”


