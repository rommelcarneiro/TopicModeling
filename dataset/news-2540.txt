


To figure out how President Obama won re-election in a slightly older and white electorate, The Upshot built a model using pre-election polling and census data to estimate the support and turnout of more than 8,000 demographic groups.

Here’s some of what you might want to know about what we did, its strengths and weaknesses.

How does this work?

The estimates are based on two models: One uses more than 15,000 interviews from pre-election polls to estimate how people voted based on their demographic characteristics; the other uses the data from the census’s Current Population Survey to estimate whether people voted based on the same factors. The type of model we’re using is good for estimating small demographic groups because it partly pools data: The estimate for Hispanic voters in Florida isn’t informed just by the 44 respondents there, but from respondents all over the country. The estimates are then adjusted to match the result. If you want more details, we’re closely following the procedures outlined in this paper by Yair Ghitza and Andrew Gelman. The code, data and a more technical discussion are available here.

What does it show?

On balance, the estimates are startlingly similar to the exit polls. It’s about as close as we would expect if it were a second exit poll.

On average, our estimates for Mr. Obama’s share of the vote differ from the exit polls by just 1 percentage point across race, age, sex, education or all of those same categories for white voters. The same story even holds at the state level, where Mr. Obama’s share of the white vote differs from the exit polls by an average of 1.4 points.

It might seem a little weird to emphasize the similarities with the exit poll in a project that generally pushes back against the exit polls. But the exit poll really is a very good survey — it falters only if it’s subjected to the sort of exacting demographic analysis that it simply isn’t designed to withstand. The similarity between the exit poll and Upshot results is reason for confidence in both.

Is this better than the exit polls?

Almost all of the differences between our findings and the exit polls are because of differences in the composition of the electorate. Since our electorate is based on C.P.S. data, it tends to show Democrats doing a hair better among white voters — but there would be almost no difference at all if it were not for the differences in the composition of the electorate.

One of the clearest examples is North Carolina. The exit polls showed that the black share of the electorate was higher in 2004, at 26 percent, than the 23 percent of 2008 and 2012. Yet the data from the State Board of Elections shows that the North Carolina exit polls were off by 7 percentage points in 2004, when the black voters represented 19 percent of the electorate. The black share of the electorate increased to 22 percent in 2008, and then up again to 23 percent in 2012.

The large number of white voters in 2004 had big consequences for the Democratic share of white voters. In 2004, in such a diverse electorate, the exit polls show John Kerry faring far worse among white voters than Mr. Obama did. In reality, Mr. Kerry most likely did better than the exit polls showed — and as our estimates show.

At the very least, the estimates offer an alternative picture of what happened if the census’ C.P.S. is more or less right. And if you believe that the C.P.S. is a better measure of turnout than the exit polls, then these estimates are probably better measures of vote share in the states where the C.P.S. and exit polls disagree by the most.

There are other advantages:

■ A surprising advantage is that the modeled estimates are adjusted to match the results with more precision than the exit polls. This is a bigger issue than you might guess. Nationally, the exit polls have Mr. Obama winning by 2.8 points, or about a point short of his 3.9-point victory. Our estimates are adjusted to precisely match the results.

The difference is even more pronounced in Western states, like California or Arizona, where late ballot counts broke heavily toward Democrats. The exit polls do not appear to be adjusted to reflect the so-called blue shift: the tendency for late ballots, including provisionals, to break heavily for Democrats long after Election Day.

■ Cluster effects — such as when the polls’ selection of precincts misses or over-represents a small group — are not an issue. The 2004 results for Hispanic voters, for instance, give Mr. Kerry a 58-to-41 edge among Hispanic voters. That is similar to the compilation of the 50 state exit polls, which gave Mr. Kerry a 58-to-40 advantage — rather than the infamous 53-to-44 percent victory in the national exit poll.

■ There are a lot of groups for which we have no exit poll data, where the model can help fill in the blanks. Most obvious are the 19 states where there were no exit polls in 2012. There are also many demographic categories — like 18-to-29-year-old Hispanic men in Alaska with some college education — for which neither we nor the exit polls have any survey data, but where the modeled estimates might still be illuminating. They’re not precise by any stretch. The margin of error might be plus or minus 10 points, or more. But it’s better than nothing.

For what it’s worth, we think Mr. Obama won 43 percent of 18-to-29-year-old Hispanic men with some college education in Alaska, with a mere 27 percent of them turning out to vote.

All right, so where is it worse?

Nothing is perfect, and our estimates are no exception.

A good rule is to be the most cautious about our estimates in the states where the composition of the electorate is similar to the exit polls, but where the exit polls nonetheless give meaningfully different results.

In those cases, it can be helpful to go back to previous years of exit polls and see whether the difference holds over time. If the bias isn’t consistent from cycle to cycle, the exit poll could just be off because of noise from precinct selection or smaller samples.

But if the bias is consistent, the exit polls may be picking up on something important and distinctive about a state’s population that the model doesn’t have enough sample to detect.

The sample simply is not large enough for precise state-level analysis of diverse but small populations, like Hispanic voters.

The Hispanic vote is actually about as politically diverse as the white vote by state, albeit shifted to the left by about 30 points. In some states, like New York, Hispanic voters overwhelmingly support Democrats. In much of the South, the Hispanic vote is fairly competitive.

The model clearly detects this pattern and gives Mr. Obama more support among Hispanic voters in blue states. But this important pattern isn’t everything. New York’s Hispanic population, with many Dominicans and Puerto Ricans, may be more Democratic than California’s Hispanic population, with more who have Mexican ancestry, even though the two states voted for Mr. Obama by fairly similar margins.

The model simply doesn’t have the data to make these distinctions. There are just 757 Hispanic respondents nationwide for 2012 and 374 for 2004. The sample of Hispanic voters is simply too small in any given state to convince the model that it’s looking at a real effect.

We’ve helped this issue by creating a category for race and “subregion”— like the interior West or the Deep South (big states, like New York or Florida, are left as their own subregions). This improves upon race and state — by allowing the model to see trends in regions with a large number of demographically distinctive voters but small population by state. It helps the model identify, for instance, just how badly Democrats do among white voters in the Deep South. Even so, I’d still bet on the model underestimating or missing important interstate distinctions among Hispanic voters. I’d even bet it still overestimates Democratic strength among white voters in Mississippi as well.

The model doesn’t have the data to correct for the peculiarities of a state’s Hispanic population. Public pollsters don’t usually record the nationality of Hispanics, which might have allowed us to distinguish between, say, voters of Dominican and Mexican ancestry. The polls don’t record the county of voters, either, which might have placed many of New York’s Hispanic voters in heavily Democratic New York City, rather than more competitive or even Republican parts of Southern and central California. If public pollsters are interested in using their polls for this sort of modeling in the future, adding additional demographic and geographic variables could be very helpful.

The exit polls have many of their own challenges, but they do have one advantage in this area: the size of the state exit polls, which gives them a much better chance of detecting something peculiar or distinctive about a small subgroup in a state. There were 698 Hispanic voters in the Florida exit poll, nearly as many as we have for the entire country.

As a result, they deserve extra consideration in the states where they show very different results from our estimates among Hispanic or “other” voters, and where those groups represent a large share of the electorate. Fortunately, Florida is not one of those states. The exit polls give Mr. Obama 60 percent of the Hispanic vote; our estimates give him 58 percent.

The clearest example is New York. In 2004 and 2012, the exit polls gave the Democratic nominee 75 and 88 percent of the Hispanic vote, while The Upshot’s model gave Mr. Obama 69 and 79 percent of the vote. That bias is consistent enough (it holds in 2000 as well) that I would assume the exit polls are picking up on something real that our model simply can’t pick up with the available data. For that same reason, my guess is that our model slightly overstates Democratic strength among white voters in New York.

Similarly, I think the model struggles to fully capture the extent of racial polarization in the Deep South. There just aren’t enough respondents there to convince the model that it can really be as bad as it probably is.

There are similar issues in states with a large number of voters who are Asian-American, Native American or some other race. Unfortunately, some of the polls used by the model clump all of these groups together — so our model clumps them together as well.

The good news is that these biases tend to be consistent. So, interestingly, the exit poll and our model show the same change in Mr. Obama’s share among white voters in New York or Mississippi and Alabama, even though they differ on vote share.


