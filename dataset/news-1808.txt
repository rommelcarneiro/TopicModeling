


More than any other company in tech, Apple prizes physical objects — expensive, perfectly designed, self-contained nuggets of aluminum and glass that you buy today, use for a couple years and replace.

Until recently, that view worked quite well. Over the past decade, through its own products and the many copycats that piled on, Apple’s device-centric aestheticism has made computers easier to use and more accessible to more people around the world — and raked in eye-popping profits while doing so.

Yet Apple’s view increasingly feels like an outdated way of thinking about tech.

Many of its competitors have been moving beyond devices toward experiences that transcend them. These new technologies exist not on distinct pieces of hardware, but above and within them. They are things like Alexa, Amazon’s ambient assistant, which lives on the internet and is ready to help you on the Amazon Echo but also on any other device that a programmer adds it to. In an era of flat iPhone sales, Apple, too, has been talking up the importance of online services, which it sees as a crucial part of its future growth.

So the primary question Apple had to answer at its annual developer conference this week was whether it could expand its worldview. Could it break free from the limiting perspective of individual devices?

The answer: Yes, but slowly — and it’s hard to tell if Apple is thinking big enough.

What was obvious in the hurricane of new features unveiled by Timothy D. Cook, Apple’s chief executive, and his lieutenants was that they understood the importance of cloud-based services. Many of Apple’s announcements featured some role for the internet to integrate people’s experiences on disparate Apple devices, often with the help of artificial intelligence.

But a lot of these features felt small bore. Apple still seems to view online services as add-ons to its devices — not as products or platforms that rise above them. The best way to see the shortcomings of this position is through Siri, the voice assistant that is Apple’s best chance to create the kind of transcendent, cross-device experience that its competitors are now pushing.

Analysts and developers were expecting big improvements to Siri. Apple did show off a way for some apps to integrate with Siri and for Siri to perform a few new functions on Apple TV; Siri also found a new home on Macintosh computers. But the way Apple presented the changes, with each Siri advance positioned as a feature of one of Apple’s devices, left unclear what Apple’s ultimate aims were for the voice assistant.

The new features fall short of remaking Siri into something fundamentally different from what it is today. Siri, as Apple is positioning it, is becoming a better app launcher for your phone — you can use it to call for an Uber ride or to respond to a message. But it’s not clear that it’s becoming a truly intelligent assistant, one that understands you across your devices, that can comprehend complex queries and get things done for you regardless of which apps you happen to have installed on any particular machine.

These shortcomings are not terrible. Though many competitors have shown off some interesting demos, at the moment no rival voice assistant approaches the accuracy and ease of use of an actual human assistant. Siri is hardly behind, and there is still room for it to become the leader. Yet the way Apple approaches Siri is a proxy for the way it plans to approach online services generally.

Before we get to the limitations, here are the details on what’s new with Siri: First, the voice assistant can now control some third-party apps on your phone. You can send text messages through apps like WhatsApp or Slack using your voice — in the past, you could do so only with Apple’s own messaging app. Depending on which developers add Siri to their apps, you might also be able to use your voice to call a ride from Uber or Lyft, to pay someone through Venmo or to tell a fitness app to start tracking your workout.

Siri’s other new trick is Mac compatibility. You can now ask your desktop or laptop to search through your files or email, for instance.

These are all fine improvements. But I am struck by the deliberate way Apple is rolling them out. One problem is that the new Siri will not integrate with all kinds of apps. It will be able to control only a handful of app types, including messaging apps, ride-sharing apps, payment apps and fitness apps. Yet Siri won’t let you control music apps, for example — you can’t ask Siri to play a song on Spotify, a feature reserved for use with Apple’s own music subscription service.

This limitation could be relaxed with time. Apple reps told me the third-party integrations they had outlined so far were the start of a new effort — one that could be expanded to new app types in the future. Still, the lack of music support was a letdown. It’s hard to shake the suspicion that Apple is using Siri to give its own apps a leg up.

Another problem is that Siri is still hopelessly tied to each Apple device. Siri on your iPhone doesn’t really know anything about Siri on your Mac or Apple TV. On each device, Siri has different capabilities: On your iPhone it can call an Uber, if you have the Uber app installed, but Siri on your Mac can’t. Siri on your Apple TV can search YouTube for clips of Stephen Curry, but Siri on your iPhone can’t.

For now, this isn’t a big problem — you will learn what Siri can do on each device and adjust your queries accordingly. But that’s a curious thing to have to do. If Siri is an intelligent assistant, why does she need to be tied to apps you have installed on your device? Why can’t she call Uber from the cloud, regardless of which device you happen to be using?

The device-centric view gets particularly limiting when you think about asking your assistant complicated questions. For instance, what if you ask, “Can you see if there’s a room at my favorite Seattle hotel for my wedding anniversary weekend — and can you book it if it’s less than $200 a night?”

Google, in its demo for Home, a forthcoming voice assistant device meant to rival Amazon’s Echo, seemed to be able to handle such questions. Two start-ups — Viv, which was founded by members of the team that created the original Siri app that Apple bought in 2010, and SoundHound have also unveiled systems that can tackle such complex queries.

To handle these questions, an assistant would need to pull information from multiple online services. For instance, booking that Seattle hotel would involve knowing your favorite place to stay, your wedding anniversary date and current hotel prices. It wouldn’t make sense if that question worked only on certain devices or only if you had certain apps installed; ideally, it should work on any device.

And that would be very useful. One of the frustrations of the era ushered in by the iPhone is app overload — there are too many apps to download, install and switch between to get anything done. A lot of these apps are of little use: You might tap that hotel-booking app once a year, so why does it have to sit there on your phone?

Voice interfaces could usher in a new paradigm in computing, one that would break free of the tyranny of apps on devices. They could get a lot done for us without much tapping and switching. Google, Amazon and several start-ups seem to be rushing headlong to build such a system.

But based on its developer conference, I’m not sure Apple is. It’s taking a more moderate app-based, device-centric path. Many of its voice features will be fine — useful, even. But it sure isn’t pushing for a revolution.


